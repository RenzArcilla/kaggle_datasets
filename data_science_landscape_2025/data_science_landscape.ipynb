{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44882176",
   "metadata": {},
   "source": [
    "## TARGET INSIGHTS\n",
    "### 1. unique job titles \n",
    "### 2. job title with highest count\n",
    "### 3. job titles with highest ave salary\n",
    "### 4. salary range for data science position\n",
    "### 5. unique skills listed for each job title \n",
    "### 6. seniority level of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0ad8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a44db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('dataset/data_science_job_posts_2025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a10436",
   "metadata": {},
   "source": [
    "## Familiarizing with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d329721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check number of rows and cols\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632efa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        job_title seniority_level   status      company  \\\n",
      "0  data scientist          senior   hybrid  company_003   \n",
      "1  data scientist            lead   hybrid  company_005   \n",
      "2  data scientist          senior  on-site  company_007   \n",
      "3  data scientist          senior   hybrid  company_008   \n",
      "4  data scientist             NaN  on-site  company_009   \n",
      "\n",
      "                                            location    post_date  \\\n",
      "0                             Grapevine, TX . Hybrid  17 days ago   \n",
      "1                            Fort Worth, TX . Hybrid  15 days ago   \n",
      "2  Austin, TX . Toronto, Ontario, Canada . Kirkla...  a month ago   \n",
      "3  Chicago, IL . Scottsdale, AZ . Austin, TX . Hy...   8 days ago   \n",
      "4                                            On-site   3 days ago   \n",
      "\n",
      "            headquarter       industry ownership company_size  revenue  \\\n",
      "0   Bentonville, AR, US         Retail    Public     €352.44B   Public   \n",
      "1       Detroit, MI, US  Manufacturing    Public      155,030  €51.10B   \n",
      "2  Redwood City, CA, US     Technology    Public       25,930  €33.80B   \n",
      "3      San Jose, CA, US     Technology    Public       34,690  €81.71B   \n",
      "4      Stamford, CT, US        Finance   Private        1,800  Private   \n",
      "\n",
      "                salary                                             skills  \n",
      "0  €100,472 - €200,938  ['spark', 'r', 'python', 'scala', 'machine lea...  \n",
      "1             €118,733  ['spark', 'r', 'python', 'sql', 'machine learn...  \n",
      "2   €94,987 - €159,559  ['aws', 'git', 'python', 'docker', 'sql', 'mac...  \n",
      "3  €112,797 - €194,402                             ['sql', 'r', 'python']  \n",
      "4  €114,172 - €228,337                                                 []  \n"
     ]
    }
   ],
   "source": [
    "# Looking at the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7358a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 944 entries, 0 to 943\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   job_title        941 non-null    object\n",
      " 1   seniority_level  884 non-null    object\n",
      " 2   status           688 non-null    object\n",
      " 3   company          944 non-null    object\n",
      " 4   location         942 non-null    object\n",
      " 5   post_date        944 non-null    object\n",
      " 6   headquarter      944 non-null    object\n",
      " 7   industry         944 non-null    object\n",
      " 8   ownership        897 non-null    object\n",
      " 9   company_size     944 non-null    object\n",
      " 10  revenue          929 non-null    object\n",
      " 11  salary           944 non-null    object\n",
      " 12  skills           944 non-null    object\n",
      "dtypes: object(13)\n",
      "memory usage: 96.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Familiarizing with the columns\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74a4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     job_title seniority_level   status      company  \\\n",
      "799             data scientist          senior  on-site  company_288   \n",
      "933  machine learning engineer        midlevel      NaN  company_941   \n",
      "592             data scientist          senior   hybrid  company_291   \n",
      "394  machine learning engineer          senior  on-site  company_065   \n",
      "283             data scientist          senior   remote  company_564   \n",
      "392             data scientist            lead      NaN  company_047   \n",
      "327             data scientist          senior      NaN  company_666   \n",
      "885             data scientist            lead  on-site  company_395   \n",
      "320             data scientist          senior   remote  company_647   \n",
      "32              data scientist          senior   hybrid  company_061   \n",
      "\n",
      "                                              location    post_date  \\\n",
      "799                            Chantilly, VA . On-site  a month ago   \n",
      "933  Bengaluru, Karnataka, India . Bangalore, Karna...  21 days ago   \n",
      "592                            Alpharetta, GA . Hybrid   7 days ago   \n",
      "394                           Toronto, Ontario, Canada  a month ago   \n",
      "283                                       Fully Remote  a month ago   \n",
      "392                  Visakhapatnam Rural mandal, India   7 days ago   \n",
      "327                               Singapore, Singapore  a month ago   \n",
      "885                                       New York, NY  21 days ago   \n",
      "320                    India, Bengaluru . Fully Remote   5 days ago   \n",
      "32        Manchester, England, United Kingdom . Hybrid  15 days ago   \n",
      "\n",
      "             headquarter    industry ownership company_size    revenue  \\\n",
      "799       Reston, VA, US  Technology    Public       26,040    €63.09B   \n",
      "933           Dublin, IE  Technology    Public      492,245   €154.21B   \n",
      "592    Bengaluru, KA, IN  Technology    Public      261,040    €71.18B   \n",
      "394  Cherry Hill, NJ, US  Technology   Private       26,030    Private   \n",
      "283    Palo Alto, CA, US  Technology   Private          300    Private   \n",
      "392    Bengaluru, KA, IN  Technology    Public      222,040    €24.46B   \n",
      "327                   SG  Technology       NaN        6,040  Education   \n",
      "885       McLean, VA, US      Retail    Public       55,150    €36.34B   \n",
      "320           London, GB  Technology   Private          900    Private   \n",
      "32        Manchester, GB  Technology    Public        1,320     Public   \n",
      "\n",
      "                  salary                                             skills  \n",
      "799             €114,169                                   ['aws', 'azure']  \n",
      "933    €10,601 - €26,376                               ['machine learning']  \n",
      "592   €85,855 - €150,244  ['pytorch', 'spark', 'aws', 'r', 'python', 'sc...  \n",
      "394  €137,008 - €173,541  ['pytorch', 'spark', 'aws', 'database', 'sql',...  \n",
      "283  €168,061 - €192,721                                                 []  \n",
      "392              €10,053              ['deep learning', 'machine learning']  \n",
      "327              €80,624                                       ['database']  \n",
      "885  €264,761 - €302,202  ['aws', 'r', 'python', 'scala', 'machine learn...  \n",
      "320              €39,026                                                 []  \n",
      "32     €45,669 - €63,936  ['spark', 'python', 'airflow', 'sql', 'machine...  \n"
     ]
    }
   ],
   "source": [
    "# Sampling the dataset\n",
    "print(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae29a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title            3\n",
      "seniority_level     60\n",
      "status             256\n",
      "company              0\n",
      "location             2\n",
      "post_date            0\n",
      "headquarter          0\n",
      "industry             0\n",
      "ownership           47\n",
      "company_size         0\n",
      "revenue             15\n",
      "salary               0\n",
      "skills               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "count_nulls = df.isnull().sum()\n",
    "print(count_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dcb6e",
   "metadata": {},
   "source": [
    "# 1. List unique job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99739d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data scientist' 'machine learning engineer' nan 'data analyst'\n",
      " 'data engineer']\n"
     ]
    }
   ],
   "source": [
    "titles = df['job_title'].unique()\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0826d8",
   "metadata": {},
   "source": [
    "# 2. Job title with highest count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1fd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title\n",
      "data scientist               856\n",
      "machine learning engineer     80\n",
      "data engineer                  4\n",
      "data analyst                   1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_titles = df['job_title'].value_counts()\n",
    "print(count_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e158e",
   "metadata": {},
   "source": [
    "# 3. Job titles with highest ave salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b257e",
   "metadata": {},
   "source": [
    "### CLEANING THE SALARY COLUMN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c41410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing salary_exact & salary_range\n",
      "         job_title  salary\n",
      "1   data scientist  118733\n",
      "8   data scientist  207331\n",
      "9   data scientist  219201\n",
      "10  data scientist   96815\n",
      "15  data scientist  134266\n",
      "\n",
      "        job_title           salary\n",
      "0  data scientist  100472 - 200938\n",
      "2  data scientist   94987 - 159559\n",
      "3  data scientist  112797 - 194402\n",
      "4  data scientist  114172 - 228337\n",
      "5  data scientist  196371 - 251170\n"
     ]
    }
   ],
   "source": [
    "# Deleting symbols: euro (€), comma (,), dot (.)\n",
    "df['salary'] = df['salary'].str.replace(r'[€,.]', '', regex=True)\n",
    "\n",
    "# Separating exact numbers and ranges\n",
    "salary_exact = df.loc[~df['salary'].str.contains('-') , :]\n",
    "salary_range = df.loc[df['salary'].str.contains('-') , :]\n",
    "\n",
    "# Checking for correctness\n",
    "print('Comparing salary_exact & salary_range')\n",
    "print(salary_exact[['job_title', 'salary']].head())\n",
    "print()\n",
    "print(salary_range[['job_title', 'salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd461ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "salary_range after get_mean()\n",
      "        job_title    salary\n",
      "0  data scientist  200941.0\n",
      "2  data scientist  174766.5\n",
      "3  data scientist  209998.0\n",
      "4  data scientist  228340.5\n",
      "5  data scientist  321956.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13928\\91326570.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_range['salary'] = salary_range['salary'].str.split(' - ')   # This will output a list of EX. [str(10), str(10)] for each row\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13928\\91326570.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_range['salary'] = salary_range['salary'].apply(get_mean)\n"
     ]
    }
   ],
   "source": [
    "# Getting the mean for ranges\n",
    "def get_mean(list_arg):\n",
    "    return int(list_arg[0]) + int(list_arg[1]) / 2\n",
    "        \n",
    "salary_range['salary'] = salary_range['salary'].str.split(' - ')   # This will output a list of EX. [str(10), str(10)] for each row\n",
    "salary_range['salary'] = salary_range['salary'].apply(get_mean)\n",
    "\n",
    "# Checking for correctness\n",
    "print('\\n' * 2)\n",
    "print('salary_range after get_mean()')\n",
    "print(salary_range[['job_title', 'salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb863f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Cleaned dataset\n",
      "        job_title    salary\n",
      "0  data scientist  118733.0\n",
      "1  data scientist  207331.0\n",
      "2  data scientist  219201.0\n",
      "3  data scientist   96815.0\n",
      "4  data scientist  134266.0\n"
     ]
    }
   ],
   "source": [
    "# Combining the dataframes\n",
    "clean_data = pd.concat([salary_exact, salary_range], ignore_index=True)\n",
    "\n",
    "# Changing the salary data type to float\n",
    "clean_data['salary'] = clean_data['salary'].astype('float')\n",
    "\n",
    "print('\\n' * 2)\n",
    "print('Cleaned dataset')\n",
    "print(clean_data[['job_title', 'salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d6f91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVE SALARIES:\n",
      "Data Scientist: €170,201\n",
      "ML Engineer: €151,007\n",
      "Data Engineer: €212,763\n",
      "Data Analyst: €69,047\n"
     ]
    }
   ],
   "source": [
    "# Getting titles with highest salary\n",
    "''' OUTPUT FROM NO#2\n",
    "data scientist               856\n",
    "machine learning engineer     80\n",
    "data engineer                  4\n",
    "data analyst                   1\n",
    "'''\n",
    "\n",
    "# Separating the data according to titles\n",
    "data_scientist = clean_data.loc[clean_data['job_title'] == 'data scientist', :]\n",
    "ml_engineer = clean_data.loc[clean_data['job_title'] == 'machine learning engineer', :]\n",
    "data_engineer = clean_data.loc[clean_data['job_title'] == 'data engineer', :]\n",
    "data_analyst = clean_data.loc[clean_data['job_title'] == 'data analyst', :]\n",
    "\n",
    "# Check for the average salary\n",
    "data_scientist_mean_salary = data_scientist.salary.sum() / data_scientist.shape[0]\n",
    "ml_engineer_mean_salary = ml_engineer.salary.sum() / ml_engineer.shape[0]\n",
    "data_engineer_mean_salary = data_engineer.salary.sum() / data_engineer.shape[0]\n",
    "data_analyst_salary = data_analyst[['job_title', 'salary']].iloc[0,1]\n",
    "\n",
    "# Converting to integer before sorting\n",
    "ds_salary = int(data_scientist_mean_salary)\n",
    "mle_salary = int(ml_engineer_mean_salary)\n",
    "de_salary = int(data_engineer_mean_salary)\n",
    "da_salary = int(data_analyst_salary)\n",
    "\n",
    "print('AVE SALARIES:')\n",
    "print(f'Data Scientist: €{ds_salary:,}')\n",
    "print(f'ML Engineer: €{mle_salary:,}')\n",
    "print(f'Data Engineer: €{de_salary:,}')\n",
    "print(f'Data Analyst: €{da_salary:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04600d",
   "metadata": {},
   "source": [
    "# 4. Salary range for data science position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3c27cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The salary range for the data scientist position based on the 2025 job posts data is €7,678.0 - €2,739,979.0\n"
     ]
    }
   ],
   "source": [
    "minimum = data_scientist.salary.min()\n",
    "maximum = data_scientist.salary.max()\n",
    "print(f\"The salary range for the data scientist position based on the 2025 job posts data is €{minimum:,} - €{maximum:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4b346",
   "metadata": {},
   "source": [
    "# 5. Unique skills listed for each job title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3a7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 600, 'machine learning': 531, 'sql': 425, 'r': 337, 'aws': 196, 'spark': 152, 'deep learning': 152, 'tensorflow': 141, 'azure': 138, 'pytorch': 121, 'tableau': 116, 'gcp': 93, 'scikit-learn': 84, 'database': 79, 'scala': 79, 'pandas': 70, 'java': 66, 'hadoop': 64, 'git': 63, 'numpy': 55, 'docker': 46, 'amazon': 45, 'kubernetes': 39, 'matplotlib': 36, 'keras': 31, 'airflow': 23, 'powerbi': 22, 'linux': 21, 'neural network': 13, 'scipy': 10, 'sklearn': 5, 'opencv': 4, 'bash': 4}\n"
     ]
    }
   ],
   "source": [
    "ds_skills = []\n",
    "\n",
    "# Iterate over the skills column using itertuples, use index=False since the index is not needed\n",
    "for row in data_scientist[['skills']].itertuples(index=False):\n",
    "    skills_list = ast.literal_eval(row.skills)   # Safely convert string values from the column EX. \"['python', 'sql']\" into a real list\n",
    "    ds_skills.extend(skills_list)   # Add the skills list into ds_skills\n",
    "\n",
    " \n",
    "ds_skills_count = Counter(ds_skills)   # Count each skill then\n",
    "print(dict(ds_skills_count.most_common()))   # Convert counter object into dict (retain order using the .most_common() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113e2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'machine learning': 48, 'python': 35, 'pytorch': 27, 'deep learning': 26, 'tensorflow': 24, 'aws': 18, 'azure': 16, 'sql': 15, 'gcp': 12, 'spark': 8, 'docker': 8, 'scikit-learn': 7, 'java': 6, 'pandas': 6, 'kubernetes': 5, 'r': 5, 'numpy': 5, 'scala': 4, 'database': 4, 'powerbi': 3, 'hadoop': 2, 'amazon': 2, 'neural network': 2, 'git': 1, 'airflow': 1, 'keras': 1}\n"
     ]
    }
   ],
   "source": [
    "mle_skills = []\n",
    "\n",
    "# Iterate over the skills column using itertuples, use index=False since the index is not needed\n",
    "for row in ml_engineer[['skills']].itertuples(index=False):\n",
    "    skills_list = ast.literal_eval(row.skills)   # Safely convert string values from the column EX. \"['python', 'sql']\" into a real list\n",
    "    mle_skills.extend(skills_list)   # Add the skills list into ds_skills\n",
    "\n",
    " \n",
    "mle_skills_count = Counter(mle_skills)   # Count each skill then\n",
    "print(dict(mle_skills_count.most_common()))   # Convert counter object into dict (retain order using the .most_common() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3815761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': 4, 'aws': 3, 'python': 2, 'scala': 2, 'sql': 2, 'spark': 1, 'hadoop': 1, 'machine learning': 1, 'java': 1, 'airflow': 1}\n"
     ]
    }
   ],
   "source": [
    "de_skills = []\n",
    "\n",
    "# Iterate over the skills column using itertuples, use index=False since the index is not needed\n",
    "for row in data_engineer[['skills']].itertuples(index=False):\n",
    "    skills_list = ast.literal_eval(row.skills)   # Safely convert string values from the column EX. \"['python', 'sql']\" into a real list\n",
    "    de_skills.extend(skills_list)   # Add the skills list into ds_skills\n",
    "\n",
    " \n",
    "de_skills_count = Counter(de_skills)   # Count each skill then\n",
    "print(dict(de_skills_count.most_common()))   # Convert counter object into dict (retain order using the .most_common() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4db48d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49    ['python']\n",
      "Name: skills, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_analyst.skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd084a2a",
   "metadata": {},
   "source": [
    "# 6. Seniority level of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01e7e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'senior': 579, 'lead': 111, 'midlevel': 98, nan: 49, 'junior': 19}\n"
     ]
    }
   ],
   "source": [
    "ds_seniority = Counter(data_scientist['seniority_level'])   # Count seniority\n",
    "ds_seniority = dict(ds_seniority.most_common())   # Convert to dictionary\n",
    "print(ds_seniority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f847a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'senior': 47, 'midlevel': 12, nan: 11, 'junior': 6, 'lead': 4}\n"
     ]
    }
   ],
   "source": [
    "mle_seniority = Counter(ml_engineer['seniority_level'])   # Count seniority\n",
    "mle_seniority = dict(mle_seniority.most_common())   # Convert to dictionary\n",
    "print(mle_seniority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b23290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'senior': 4}\n"
     ]
    }
   ],
   "source": [
    "de_seniority = Counter(data_engineer['seniority_level'])   # Count seniority\n",
    "de_seniority = dict(de_seniority.most_common())   # Convert to dictionary\n",
    "print(de_seniority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d34fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'midlevel': 1}\n"
     ]
    }
   ],
   "source": [
    "da_seniority = Counter(data_analyst['seniority_level'])   # Count seniority\n",
    "da_seniority = dict(da_seniority.most_common())   # Convert to dictionary\n",
    "print(da_seniority)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
